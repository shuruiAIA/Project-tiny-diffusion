{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting device\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the dataset MNIST, we try to use the U-NET to replace the network\n",
    "def sinusoidal_embedding(n, d):\n",
    "    # Returns the standard positional embedding\n",
    "    embedding = torch.tensor([[i / 10_000 ** (2 * j / d) for j in range(d)] for i in range(n)])\n",
    "    sin_mask = torch.arange(0, n, 2)\n",
    "\n",
    "    embedding[sin_mask] = torch.sin(embedding[sin_mask])\n",
    "    embedding[1 - sin_mask] = torch.cos(embedding[sin_mask])\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, padding=1, activation=None, normalize=True):\n",
    "        super(MyBlock, self).__init__()\n",
    "        self.ln = nn.LayerNorm(shape)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)\n",
    "        self.activation = nn.SiLU() if activation is None else activation\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ln(x) if self.normalize else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyUNet(nn.Module):\n",
    "    def __init__(self, n_steps=1000, time_emb_dim=100):\n",
    "        super(MyUNet, self).__init__()\n",
    "\n",
    "        # Sinusoidal embedding\n",
    "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.requires_grad_(False)\n",
    "\n",
    "        # First half\n",
    "        self.te1 = self._make_te(time_emb_dim, 1)\n",
    "        self.b1 = nn.Sequential(\n",
    "            MyBlock((1, 28, 28), 1, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10)\n",
    "        )\n",
    "        self.down1 = nn.Conv2d(10, 10, 4, 2, 1)\n",
    "\n",
    "        self.te2 = self._make_te(time_emb_dim, 10)\n",
    "        self.b2 = nn.Sequential(\n",
    "            MyBlock((10, 14, 14), 10, 20),\n",
    "            MyBlock((20, 14, 14), 20, 20),\n",
    "            MyBlock((20, 14, 14), 20, 20)\n",
    "        )\n",
    "        self.down2 = nn.Conv2d(20, 20, 4, 2, 1)\n",
    "\n",
    "        self.te3 = self._make_te(time_emb_dim, 20)\n",
    "        self.b3 = nn.Sequential(\n",
    "            MyBlock((20, 7, 7), 20, 40),\n",
    "            MyBlock((40, 7, 7), 40, 40),\n",
    "            MyBlock((40, 7, 7), 40, 40)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(40, 40, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(40, 40, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.te_mid = self._make_te(time_emb_dim, 40)\n",
    "        self.b_mid = nn.Sequential(\n",
    "            MyBlock((40, 3, 3), 40, 20),\n",
    "            MyBlock((20, 3, 3), 20, 20),\n",
    "            MyBlock((20, 3, 3), 20, 40)\n",
    "        )\n",
    "\n",
    "        # Second half\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(40, 40, 4, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(40, 40, 2, 1)\n",
    "        )\n",
    "\n",
    "        self.te4 = self._make_te(time_emb_dim, 80)\n",
    "        self.b4 = nn.Sequential(\n",
    "            MyBlock((80, 7, 7), 80, 40),\n",
    "            MyBlock((40, 7, 7), 40, 20),\n",
    "            MyBlock((20, 7, 7), 20, 20)\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(20, 20, 4, 2, 1)\n",
    "        self.te5 = self._make_te(time_emb_dim, 40)\n",
    "        self.b5 = nn.Sequential(\n",
    "            MyBlock((40, 14, 14), 40, 20),\n",
    "            MyBlock((20, 14, 14), 20, 10),\n",
    "            MyBlock((10, 14, 14), 10, 10)\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(10, 10, 4, 2, 1)\n",
    "        self.te_out = self._make_te(time_emb_dim, 20)\n",
    "        self.b_out = nn.Sequential(\n",
    "            MyBlock((20, 28, 28), 20, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10),\n",
    "            MyBlock((10, 28, 28), 10, 10, normalize=False)\n",
    "        )\n",
    "\n",
    "        self.conv_out = nn.Conv2d(10, 1, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x is (N, 2, 28, 28) (image with positional embedding stacked on channel dimension)\n",
    "        t = self.time_embed(t)\n",
    "        n = len(x)\n",
    "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))  # (N, 10, 28, 28)\n",
    "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))  # (N, 20, 14, 14)\n",
    "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1))  # (N, 40, 7, 7)\n",
    "\n",
    "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))  # (N, 40, 3, 3)\n",
    "\n",
    "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)  # (N, 80, 7, 7)\n",
    "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1))  # (N, 20, 7, 7)\n",
    "\n",
    "        out5 = torch.cat((out2, self.up2(out4)), dim=1)  # (N, 40, 14, 14)\n",
    "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))  # (N, 10, 14, 14)\n",
    "\n",
    "        out = torch.cat((out1, self.up3(out5)), dim=1)  # (N, 20, 28, 28)\n",
    "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))  # (N, 1, 28, 28)\n",
    "\n",
    "        out = self.conv_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_te(self, dim_in, dim_out):\n",
    "        return nn.Sequential(nn.Linear(dim_in, dim_out), nn.SiLU(), nn.Linear(dim_out, dim_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device) -> None:\n",
    "        super(DDPM, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32).to(device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.)\n",
    "        self.network = network.to(device)\n",
    "\n",
    "    def add_noise(self, x_start, x_noise, timesteps):\n",
    "        # The forward process\n",
    "\n",
    "        sqrt_alphas_cumprod = self.alphas_cumprod ** 0.5\n",
    "        sqrt_one_minus_alphas_cumprod = (1 - self.alphas_cumprod) ** 0.5\n",
    "\n",
    "        s1 = sqrt_alphas_cumprod[timesteps].to(device)\n",
    "        s2 = sqrt_one_minus_alphas_cumprod[timesteps].to(device)\n",
    "        s1 = s1.reshape(-1, 1).unsqueeze(2).unsqueeze(3)\n",
    "        s2 = s2.reshape(-1, 1).unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "        return s1 * x_start + s2 * x_noise\n",
    "\n",
    "    def reverse(self, x, t):\n",
    "        # The network return the estimation of the noise we added\n",
    "\n",
    "        return self.network.forward(x, t)\n",
    "\n",
    "    def reconstruct_x0(self, x_t, t, noise):\n",
    "\n",
    "        s1 = torch.sqrt(1 / self.alphas_cumprod)[t].to(device)\n",
    "        s2 = torch.sqrt(1 / self.alphas_cumprod - 1)[t].to(device)\n",
    "        s1 = s1.reshape(-1, 1)\n",
    "        s2 = s2.reshape(-1, 1)\n",
    "\n",
    "        return s1 * x_t - s2 * noise\n",
    "\n",
    "    def q_posterior(self, x_0, x_t, t):\n",
    "\n",
    "        posterior_mean_coef1 = (self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)).to(device)\n",
    "        posterior_mean_coef2= ((1. - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1. - self.alphas_cumprod)).to(device)\n",
    "        s1 = posterior_mean_coef1[t].to(device)\n",
    "        s2 = posterior_mean_coef2[t].to(device)\n",
    "        s1 = s1.reshape(-1, 1)\n",
    "        s2 = s2.reshape(-1, 1)\n",
    "        mu = s1 * x_0 + s2 * x_t\n",
    "\n",
    "        return mu\n",
    "\n",
    "    def get_variance(self, t):\n",
    "\n",
    "        if t == 0:\n",
    "            return 0\n",
    "\n",
    "        variance = (self.betas[t] * (1. - self.alphas_cumprod_prev[t]) / (1. - self.alphas_cumprod[t])).to(device)\n",
    "        variance = variance.clip(1e-20)\n",
    "\n",
    "        return variance\n",
    "\n",
    "    def step(self, model_output, timestep, sample):\n",
    "        \n",
    "        t = timestep\n",
    "        pred_original_sample = self.reconstruct_x0(sample, t, model_output).to(device)\n",
    "        pred_prev_sample = self.q_posterior(pred_original_sample, sample, t).to(device)\n",
    "\n",
    "        variance = 0\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(model_output).to(device)\n",
    "            variance = ((self.get_variance(t) ** 0.5) * noise).to(device)\n",
    "\n",
    "        pred_prev_sample = pred_prev_sample + variance\n",
    "\n",
    "        return pred_prev_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device):\n",
    "    global_step = 0\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(total=len(dataloader))\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            batch = batch[0].to(device)\n",
    "            noise = torch.randn(batch.shape).to(device)\n",
    "            timesteps = torch.randint(0, num_timesteps, (batch.shape[0],)).long().to(device)\n",
    "\n",
    "            noisy = model.add_noise(batch, noise, timesteps)\n",
    "            noise_pred = model.reverse(noisy, timesteps)\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
    "            losses.append(loss.detach().item())\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            global_step += 1\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 12720108.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 40005182.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 11088383.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 8840152.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 200\n",
    "num_timesteps = 1000\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "network = MyUNet()\n",
    "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▌         | 24/469 [00:23<07:06,  1.04it/s, loss=0.636, step=23]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device\u001b[39m=\u001b[39;49mdevice)\n",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, dataloader, optimizer, num_epochs, num_timesteps, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/map583-H-oY7asF-py3.9/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/map583-H-oY7asF-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(ddpm, sample_size, channel, height, width):\n",
    "\n",
    "    frames = []\n",
    "    with torch.no_grad():\n",
    "        timesteps = list(range(ddpm.num_timesteps))[::-1]\n",
    "        sample = torch.randn(sample_size, channel, height, width).to(device)\n",
    "        \n",
    "        for i, t in enumerate(tqdm(timesteps)):\n",
    "            time_tensor = (torch.ones(sample_size, 1) * t).long().to(device)\n",
    "            residual = ddpm.reverse(sample, time_tensor).to(device)\n",
    "            sample = ddpm.step(residual, time_tensor[0], sample)\n",
    "        sample = torch.squeeze(sample)\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            frames.append(sample[i].detach().cpu().numpy())\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generate_image(model, 50, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title=\"\"):\n",
    "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
    "\n",
    "    # Converting images to CPU numpy arrays\n",
    "    if type(images) is torch.Tensor:\n",
    "        images = images.detach().cpu().numpy()\n",
    "\n",
    "    # Defining number of rows and columns\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images) ** (1 / 2))\n",
    "    cols = round(len(images) / rows)\n",
    "\n",
    "    # Populating figure with sub-plots\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows, cols, idx + 1)\n",
    "\n",
    "            if idx < len(images):\n",
    "                plt.imshow(images[idx], cmap=\"gray\")\n",
    "                idx += 1\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    # Showing the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(generated, \"Final result\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map583-H-oY7asF-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b567ae1ed40eec8e99fb4e569067de5f3f24746ca826c93811e359dcb2fbcbf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
